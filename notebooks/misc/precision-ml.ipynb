{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1427abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from itertools import product, islice\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "from optimizers import GradientSearch, ConjugateGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b78e1b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "########### Set Device ############\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "dtype = torch.float64\n",
    "torch.set_default_dtype(dtype)\n",
    "print(\"Using device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66bd5eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# although this method allows for nice-looking code, it is too slow\n",
    "# for large batch sizes to iterate within python through inputs\n",
    "\n",
    "# def loader_for_function(f, ranges, device=device, dtype=dtype):\n",
    "#     def get_batch(N=1000):\n",
    "#         xs = []\n",
    "#         ys = []\n",
    "#         for _ in range(N):   \n",
    "#             x = tuple(r1 + (r2 - r1) * np.random.rand() for r1, r2 in ranges)\n",
    "#             y = f(*x)\n",
    "#             xs.append(x)\n",
    "#             ys.append(y)\n",
    "#         xs = torch.tensor(xs).to(dtype).to(device)\n",
    "#         ys = torch.tensor(ys).unsqueeze(1).to(dtype).to(device)\n",
    "#         return xs, ys\n",
    "    \n",
    "#     return get_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49b3628",
   "metadata": {},
   "source": [
    "### Let's see what kind of accuracy we can get on the identity f(x) = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "631d6b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4b0e3914f541259942310aab90bc96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6215136914354132\n",
      "0.016632206740054164\n",
      "0.008221486522347624\n",
      "0.009169951476469337\n",
      "0.00685257831441799\n",
      "0.008023308464678752\n",
      "0.00679671055176372\n",
      "0.008869029340940868\n",
      "0.0066730895331963015\n",
      "0.005886731526323771\n",
      "0.009131280998136293\n",
      "0.007582855183800114\n",
      "0.005454468589275011\n",
      "0.007773877961192291\n",
      "0.007977107162661598\n",
      "0.006975031095137714\n",
      "0.0069035481941631584\n",
      "0.007450874830133905\n",
      "0.007500273508325325\n",
      "0.004167638383897212\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "steps = 1000\n",
    "\n",
    "def batch_loader(N=batch_size, device=device, dtype=dtype):\n",
    "    x = torch.rand((N, 1), device=device, dtype=dtype)\n",
    "    return x, x\n",
    "\n",
    "width = 200\n",
    "mlp = nn.Sequential(\n",
    "    nn.Linear(1, width),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(width, width),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(width, 1)\n",
    ").to(device)\n",
    "\n",
    "loss_fn = lambda x, y: torch.sqrt(torch.mean(torch.pow(x - y, 2)))\n",
    "# loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(mlp.parameters())\n",
    "\n",
    "for i in tqdm(range(steps)):\n",
    "    optimizer.zero_grad()\n",
    "    x, y = batch_loader(batch_size)\n",
    "    loss = loss_fn(mlp(x), y)\n",
    "    if i % (steps // 20) == 0:\n",
    "        print(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c00cae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a0fe9ef056e46298c0744cde577f16c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3402119097494031\n",
      "0.0038755328257858643\n",
      "0.0027832232089777804\n",
      "0.001957876152971073\n",
      "0.0013187170135408354\n",
      "0.0012577637974300999\n",
      "0.0008789397889795287\n",
      "0.0006812021540133076\n",
      "0.0005070912454314665\n",
      "0.00047577732695577103\n",
      "0.0003311467404238318\n",
      "0.00031014630712091065\n",
      "0.0002551778054488398\n",
      "0.00020023424261374591\n",
      "0.00014436231955539314\n",
      "0.00012453629987910342\n",
      "9.370422506429543e-05\n",
      "9.044399149075197e-05\n",
      "6.128427187672664e-05\n",
      "5.7458615048336796e-05\n",
      "4.921363691350252e-05\n",
      "4.785105796230194e-05\n",
      "2.573895153549037e-05\n",
      "2.3995503304544258e-05\n",
      "2.0669365310416863e-05\n",
      "1.781653741071639e-05\n",
      "1.6320878909139857e-05\n",
      "1.5448738049522897e-05\n",
      "1.5149893748034199e-05\n",
      "1.5194231085639418e-05\n",
      "1.4382337285767065e-05\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "steps = 100000\n",
    "\n",
    "def batch_loader(N=batch_size, device=device, dtype=dtype):\n",
    "    x = torch.rand((N, 1), device=device, dtype=dtype)\n",
    "    return x, x\n",
    "\n",
    "width = 200\n",
    "mlp = nn.Sequential(\n",
    "    nn.Linear(1, width),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(width, width),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(width, 1)\n",
    ").to(device)\n",
    "\n",
    "loss_fn = lambda x, y: torch.sqrt(torch.mean(torch.pow(x - y, 2)))\n",
    "# loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(mlp.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8)\n",
    "\n",
    "for i in tqdm(range(steps)):\n",
    "    optimizer.zero_grad()\n",
    "    x, y = batch_loader(batch_size)\n",
    "    loss = loss_fn(mlp(x), y)\n",
    "    if i % (steps // 30) == 0:\n",
    "        print(loss.item())\n",
    "        scheduler.step()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88a1157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(size=500, magnitude=5.0, device=device, dtype=dtype):\n",
    "    x = 2 * magnitude * torch.rand((size, 2), dtype=dtype) - magnitude\n",
    "    y = torch.unsqueeze(torch.prod(x, dim=1), dim=1)\n",
    "    return x.to(device), y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f6c124d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1837.8159642335986\n",
      "9.99063111981725e-06\n",
      "1.5689027854239416e-06\n",
      "1.5662918368236948e-06\n",
      "1.566570273820423e-06\n",
      "1.5687781653125516e-06\n",
      "1.5691333798480043e-06\n",
      "1.5699990578855427e-06\n",
      "1.5665213241379912e-06\n",
      "1.5658878766714352e-06\n"
     ]
    }
   ],
   "source": [
    "mlp = nn.Sequential(\n",
    "    nn.Linear(2, 4, bias=False),\n",
    "    nn.Softplus(),\n",
    "    nn.Linear(4, 1, bias=False)\n",
    ").to(device)\n",
    "\n",
    "# loss_fn = lambda x, y: torch.sqrt(torch.mean(torch.pow(x - y, 2)))\n",
    "loss_fn = nn.MSELoss()\n",
    "# loss_fn = lambda x, y: torch.mean(0.5 * torch.log(1.0 + torch.pow(x - y, 2)))\n",
    "lambduh = 0.00001\n",
    "sigma_2nd_der = 1 / 4\n",
    "mu = np.power(lambduh, -2) / (4 * sigma_2nd_der)\n",
    "\n",
    "mlp[0].weight.data[0, 0] = lambduh\n",
    "mlp[0].weight.data[0, 1] = lambduh\n",
    "mlp[0].weight.data[1, 0] = -lambduh\n",
    "mlp[0].weight.data[1, 1] = -lambduh\n",
    "mlp[0].weight.data[2, 0] = lambduh\n",
    "mlp[0].weight.data[2, 1] = -lambduh\n",
    "mlp[0].weight.data[3, 0] = -lambduh\n",
    "mlp[0].weight.data[3, 1] = lambduh\n",
    "\n",
    "mlp[2].weight.data[0, 0] = mu\n",
    "mlp[2].weight.data[0, 1] = mu\n",
    "mlp[2].weight.data[0, 2] = -mu\n",
    "mlp[2].weight.data[0, 3] = -mu\n",
    "\n",
    "# perturb\n",
    "mlp[0].weight.data += 0.000000001 * torch.randn(mlp[0].weight.shape).to(device)\n",
    "# mlp[2].weight.data += 0.000000001 * torch.randn(mlp[2].weight.shape).to(device)\n",
    "\n",
    "optimizer = ConjugateGradients(mlp.parameters())\n",
    "# optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-8)\n",
    "\n",
    "def get_loss_on(x, y):\n",
    "    def loss():\n",
    "        return loss_fn(mlp(x), y)\n",
    "    return loss\n",
    "\n",
    "for t in range(10):\n",
    "    x, y = get_batch(size=5000000, device=device)\n",
    "    for param in mlp.parameters():\n",
    "        param.grad = None\n",
    "    loss = loss_fn(mlp(x), y)\n",
    "    print(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step(get_loss_on(x, y))\n",
    "#     optimizer.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3158276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4541.355698439289\n",
      "0.00024350339322852722\n",
      "1.6888223747325525e-06\n",
      "1.6167086323486558e-06\n",
      "1.6132424365053562e-06\n",
      "1.6155498028812036e-06\n",
      "1.6160667856715122e-06\n",
      "1.6183325045384076e-06\n",
      "1.6157386511744902e-06\n",
      "1.6172515571821007e-06\n"
     ]
    }
   ],
   "source": [
    "mlp = nn.Sequential(\n",
    "    nn.Linear(2, 4, bias=False),\n",
    "    nn.Softplus(),\n",
    "    nn.Linear(4, 1, bias=False)\n",
    ").to(device)\n",
    "\n",
    "# loss_fn = lambda x, y: torch.sqrt(torch.mean(torch.pow(x - y, 2)))\n",
    "loss_fn = nn.MSELoss()\n",
    "# loss_fn = lambda x, y: torch.mean(0.5 * torch.log(1.0 + torch.pow(x - y, 2)))\n",
    "lambduh = 0.00001\n",
    "sigma_2nd_der = 1 / 4\n",
    "mu = np.power(lambduh, -2) / (4 * sigma_2nd_der)\n",
    "\n",
    "mlp[0].weight.data[0, 0] = lambduh\n",
    "mlp[0].weight.data[0, 1] = lambduh\n",
    "mlp[0].weight.data[1, 0] = -lambduh\n",
    "mlp[0].weight.data[1, 1] = -lambduh\n",
    "mlp[0].weight.data[2, 0] = lambduh\n",
    "mlp[0].weight.data[2, 1] = -lambduh\n",
    "mlp[0].weight.data[3, 0] = -lambduh\n",
    "mlp[0].weight.data[3, 1] = lambduh\n",
    "\n",
    "mlp[2].weight.data[0, 0] = mu\n",
    "mlp[2].weight.data[0, 1] = mu\n",
    "mlp[2].weight.data[0, 2] = -mu\n",
    "mlp[2].weight.data[0, 3] = -mu\n",
    "\n",
    "# perturb\n",
    "mlp[0].weight.data += 0.000000001 * torch.randn(mlp[0].weight.shape).to(device)\n",
    "# mlp[2].weight.data += 0.000000001 * torch.randn(mlp[2].weight.shape).to(device)\n",
    "\n",
    "# optimizer = ConjugateGradients(mlp.parameters())\n",
    "# optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-8)\n",
    "optimizer = torch.optim.LBFGS(mlp.parameters(), line_search_fn='strong_wolfe')\n",
    "\n",
    "def get_loss_on(x, y):\n",
    "    def loss():\n",
    "        return loss_fn(mlp(x), y)\n",
    "    return loss\n",
    "\n",
    "for t in range(10):\n",
    "    x, y = get_batch(size=5000000, device=device)\n",
    "    for param in mlp.parameters():\n",
    "        param.grad = None\n",
    "    loss = loss_fn(mlp(x), y)\n",
    "    print(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step(get_loss_on(x, y))\n",
    "#     optimizer.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "416e2c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15bb5f9a7aad44bc9ff16bbd6efa414b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34346171468939457\n",
      "8.294543685305164e-05\n",
      "1.8324633178244746e-05\n",
      "1.5079140671388769e-05\n",
      "1.2482727931885166e-06\n",
      "8.041948588398111e-07\n",
      "6.935735764317089e-07\n",
      "7.178304960709016e-07\n",
      "7.048249439302676e-07\n",
      "6.61595078429851e-07\n",
      "6.169023720261465e-07\n",
      "6.674474383852554e-07\n",
      "7.463504492384863e-07\n",
      "7.023326050895587e-07\n",
      "6.826318520554893e-07\n",
      "6.589996260773685e-07\n",
      "6.653843877715709e-07\n",
      "6.633753570108896e-07\n",
      "6.977112082560682e-07\n",
      "6.812314341249032e-07\n",
      "6.767246152840558e-07\n",
      "6.863075445666013e-07\n",
      "6.451450297818992e-07\n",
      "6.570866426872617e-07\n",
      "6.620975636743754e-07\n",
      "6.720849508881183e-07\n",
      "6.704449149065174e-07\n",
      "6.691755201551307e-07\n",
      "6.208549037832126e-07\n",
      "6.539695993544596e-07\n",
      "6.465091557074017e-07\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "steps = 1000\n",
    "\n",
    "def batch_loader(N=batch_size, device=device, dtype=dtype):\n",
    "    x = torch.rand((N, 1), device=device, dtype=dtype)\n",
    "    return x, x\n",
    "\n",
    "width = 1000\n",
    "mlp = nn.Sequential(\n",
    "    nn.Linear(1, width),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(width, width),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(width, 1)\n",
    ").to(device)\n",
    "\n",
    "# loss_fn = lambda x, y: torch.sqrt(torch.mean(torch.pow(x - y, 2)))\n",
    "loss_fn = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(mlp.parameters())\n",
    "optimizer = torch.optim.LBFGS(mlp.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8)\n",
    "\n",
    "def get_loss_on(x, y):\n",
    "    def loss():\n",
    "        return loss_fn(mlp(x), y)\n",
    "    return loss\n",
    "\n",
    "for i in tqdm(range(steps)):\n",
    "    optimizer.zero_grad()\n",
    "    x, y = batch_loader(batch_size)\n",
    "    loss = loss_fn(mlp(x), y)\n",
    "    if i % (steps // 30) == 0:\n",
    "        print(loss.item())\n",
    "        scheduler.step()\n",
    "    loss.backward()\n",
    "    optimizer.step(get_loss_on(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b52481a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006520323989782889"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt(torch.mean(torch.pow(mlp(x) - y, 2))).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931ec2fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d6d25f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d5ccd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4e1554e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c1e7ec2f7c4a8f9c2f168cd4e8b992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5802282766689215\n",
      "0.012556786702098652\n",
      "0.008603945423605049\n",
      "0.007910701846506111\n",
      "0.004467205770984088\n",
      "0.004192988165117967\n",
      "0.004109117304133539\n",
      "0.003967926173327114\n",
      "0.0038609906074635434\n",
      "0.003862112513919313\n",
      "0.003750203328066008\n",
      "0.0036848227795535245\n",
      "0.0036846037636736337\n",
      "0.0036249718026108097\n",
      "0.003604131056705896\n",
      "0.003525027808091917\n",
      "0.0035075534273216343\n",
      "0.003455586490789744\n",
      "0.003345644791616197\n",
      "0.0033491081856328476\n",
      "0.0033172437176913648\n",
      "0.0033712126528068036\n",
      "0.0033005015079467653\n",
      "0.003332339627846163\n",
      "0.0033045612881356166\n",
      "0.0033529064160614133\n",
      "0.0033120300454531383\n",
      "0.0032889802652026202\n",
      "0.0032506353441967947\n",
      "0.0032517986600214305\n",
      "0.003249013608719287\n",
      "0.003267867745909247\n",
      "0.003293020826915775\n",
      "0.003285123374865273\n",
      "0.003254319808781407\n",
      "0.0032370786269321646\n",
      "0.0032268431692896384\n",
      "0.0032374681693674015\n",
      "0.003243107964870443\n",
      "0.0032381076791539124\n",
      "0.003244658186640452\n",
      "0.0032379139418580384\n",
      "0.003197489636487112\n",
      "0.003261862933622493\n",
      "0.0032032690025550294\n",
      "0.0031807588289789043\n",
      "0.0031849301184814177\n",
      "0.0031803319786130827\n",
      "0.0031640251832205655\n",
      "0.0031971571818553064\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10000\n",
    "steps = 1000\n",
    "\n",
    "def batch_loader(N=batch_size, device=device, dtype=dtype):\n",
    "    x = torch.rand((N, 1), device=device, dtype=dtype)\n",
    "    return x, x\n",
    "\n",
    "width = 200\n",
    "mlp = nn.Sequential(\n",
    "    nn.Linear(1, width),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(width, width),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(width, 1)\n",
    ").to(device)\n",
    "\n",
    "loss_fn = lambda x, y: torch.sqrt(torch.mean(torch.pow(x - y, 2)))\n",
    "# loss_fn = nn.MSELoss()\n",
    "optimizer = GradientSearch(mlp.parameters())\n",
    "\n",
    "def get_loss_on(x, y):\n",
    "    def loss():\n",
    "        return loss_fn(mlp(x), y)\n",
    "    return loss\n",
    "\n",
    "for i in tqdm(range(steps)):\n",
    "    optimizer.zero_grad()\n",
    "    x, y = batch_loader(batch_size)\n",
    "    loss = loss_fn(mlp(x), y)\n",
    "    if i % (steps // 50) == 0:\n",
    "        print(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step(get_loss_on(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4762352a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "248d2943edb349e1b85c95713fa458f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.596597865964254\n",
      "0.16527397928980034\n",
      "0.1515326103583527\n",
      "0.12388647054772055\n",
      "0.1058342509837756\n",
      "0.09510941664016952\n",
      "0.08841844748891863\n",
      "0.08313431210326361\n",
      "0.07802141841159543\n",
      "0.0743273198164449\n",
      "0.07038349717089902\n",
      "0.06771809303288238\n",
      "0.06441873136843128\n",
      "0.06196300562135732\n",
      "0.05877941664365911\n",
      "0.05768720616689987\n",
      "0.055286087914244296\n",
      "0.05489223323917382\n",
      "0.05063932382366036\n",
      "0.04886912335846623\n",
      "0.047339204914950056\n",
      "0.04776486004578241\n",
      "0.044343422531500545\n",
      "0.04549187640841335\n",
      "0.04285294864178607\n",
      "0.0433429924137831\n",
      "0.03953854394231662\n",
      "0.04159739203324057\n",
      "0.03798115266895868\n",
      "0.03890225028658445\n",
      "0.036683728382152773\n",
      "0.038020987150284104\n",
      "0.03496047321120063\n",
      "0.03682813268302742\n",
      "0.034043346057094845\n",
      "0.035623425493341354\n",
      "0.03193717006690031\n",
      "0.034156529441688926\n",
      "0.031292762020494115\n",
      "0.03265197591810669\n",
      "0.029619189848940724\n",
      "0.03127272741571547\n",
      "0.029073286323050413\n",
      "0.03068533537330858\n",
      "0.02986133106196708\n",
      "0.030609974531465797\n",
      "0.027873955254147098\n",
      "0.027963292022968097\n",
      "0.027878259359813338\n",
      "0.02879676591362524\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c4b411ec7614907af6bd10a24771465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025505997099907977\n",
      "0.0008302708066344926\n",
      "0.0008340144396651931\n",
      "0.0008320717060894202\n",
      "0.0008277521627004315\n",
      "0.0008219682901235305\n",
      "0.0008204126082111068\n",
      "0.0008238528688335803\n",
      "0.0008175449557135757\n",
      "0.0008205425263474627\n",
      "0.0008119143039377235\n",
      "0.0008000305231799252\n",
      "0.0008094692983450749\n",
      "0.0008130712978199151\n",
      "0.0008136199736661495\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12904/1704844622.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_loss_on\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/noisy/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/noisy/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/explore/precision-ml/optimizers.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0md_p_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                 \u001b[0mbest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 best_params_with_grad_data = [param.data.detach().clone()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 10000\n",
    "steps = 1000\n",
    "\n",
    "def batch_loader(N=batch_size, device=device, dtype=dtype):\n",
    "    x = torch.rand((N, 1), device=device, dtype=dtype)\n",
    "    return x, x\n",
    "\n",
    "width = 200\n",
    "mlp = nn.Sequential(\n",
    "    nn.Linear(1, width),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(width, width),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(width, 1)\n",
    ").to(device)\n",
    "\n",
    "loss_fn = lambda x, y: torch.sqrt(torch.mean(torch.pow(x - y, 2)))\n",
    "# loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(mlp.parameters())\n",
    "\n",
    "for i in tqdm(range(steps)):\n",
    "    optimizer.zero_grad()\n",
    "    x, y = batch_loader(batch_size)\n",
    "    loss = loss_fn(mlp(x), y)\n",
    "    if i % (steps // 50) == 0:\n",
    "        print(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "def get_loss_on(x, y):\n",
    "    def loss():\n",
    "        return loss_fn(mlp(x), y)\n",
    "    return loss\n",
    "\n",
    "optimizer = GradientSearch(mlp.parameters())\n",
    "    \n",
    "for i in tqdm(range(steps)):\n",
    "    optimizer.zero_grad()\n",
    "    x, y = batch_loader(batch_size)\n",
    "    loss = loss_fn(mlp(x), y)\n",
    "    if i % (steps // 50) == 0:\n",
    "        print(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step(get_loss_on(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f476bea1",
   "metadata": {},
   "source": [
    "## Okay let's just try a bunch of random shit to try to learn the identity function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a5a84e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c54d779556a64283b8c23ee8e19030ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.614834112592495\n",
      "0.0003633449159704096\n",
      "0.00020521464029633275\n",
      "0.00014448931503282205\n",
      "0.00011501259417822816\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82a5db621fb460b83d830baa00af320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.061560756392602e-05\n",
      "8.928837762082247e-05\n",
      "8.902337959107016e-05\n",
      "9.020798614406398e-05\n",
      "8.883517442331253e-05\n",
      "8.898283808821932e-05\n",
      "8.839890101434467e-05\n",
      "8.768438693549308e-05\n",
      "8.791384083326228e-05\n",
      "8.844376522344286e-05\n",
      "8.947725667495323e-05\n",
      "8.865961795774977e-05\n",
      "8.939803022540401e-05\n",
      "8.92787223952501e-05\n",
      "8.890599408016156e-05\n",
      "9.056699287134379e-05\n",
      "9.10531328100987e-05\n",
      "8.982914913874023e-05\n",
      "8.874631417956123e-05\n",
      "8.935106418505105e-05\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5000\n",
    "\n",
    "def batch_loader(N=batch_size, device=device, dtype=dtype):\n",
    "    x = torch.rand((N, 1), device=device, dtype=dtype)\n",
    "    return x, x\n",
    "\n",
    "width = 1000\n",
    "mlp = nn.Sequential(\n",
    "    nn.Linear(1, width),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(width, width),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(width, width),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(width, 1)\n",
    ").to(device)\n",
    "mlp.train()\n",
    "\n",
    "rmse_loss_fn = lambda x, y: torch.sqrt(torch.mean(torch.pow(x - y, 2)))\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(mlp.parameters())\n",
    "\n",
    "for i in tqdm(range(1000)):\n",
    "    optimizer.zero_grad()\n",
    "    x, y = batch_loader(batch_size)\n",
    "    loss = loss_fn(mlp(x), y)\n",
    "    if i % 200 == 0:\n",
    "        mlp.eval()\n",
    "        with torch.no_grad():\n",
    "            print(rmse_loss_fn(mlp(x), y).item())\n",
    "        mlp.train()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "def get_loss_on(x, y):\n",
    "    def loss():\n",
    "        return loss_fn(mlp(x), y)\n",
    "    return loss\n",
    "\n",
    "optimizer = torch.optim.LBFGS(mlp.parameters())\n",
    "    \n",
    "for i in tqdm(range(100)):\n",
    "    optimizer.zero_grad()\n",
    "    x, y = batch_loader(batch_size)\n",
    "    loss = loss_fn(mlp(x), y)\n",
    "    if i % 5 == 0:\n",
    "        mlp.eval()\n",
    "        with torch.no_grad():\n",
    "            print(rmse_loss_fn(mlp(x), y).item())\n",
    "        mlp.train()\n",
    "    loss.backward()\n",
    "    optimizer.step(get_loss_on(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a83e1c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a810bc645d347f8aa4e29925f9892ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4837442591717146\n",
      "0.00019317593698999524\n",
      "9.661586831167584e-05\n",
      "0.003966827180718762\n",
      "5.394775473416932e-05\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5000\n",
    "\n",
    "def batch_loader(N=batch_size, device=device, dtype=dtype):\n",
    "    x = torch.rand((N, 1), device=device, dtype=dtype)\n",
    "    return x, x\n",
    "\n",
    "width = 500\n",
    "mlp = nn.Sequential(\n",
    "    nn.Linear(1, width),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(width, width),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(width, width),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(width, 1)\n",
    ").to(device)\n",
    "mlp.train()\n",
    "\n",
    "rmse_loss_fn = lambda x, y: torch.sqrt(torch.mean(torch.pow(x - y, 2)))\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(mlp.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "steps = 5000\n",
    "for i in tqdm(range(steps)):\n",
    "    optimizer.zero_grad()\n",
    "    x, y = batch_loader(batch_size)\n",
    "    loss = loss_fn(mlp(x), y)\n",
    "    if i % 1000 == 0:\n",
    "        mlp.eval()\n",
    "        with torch.no_grad():\n",
    "            print(rmse_loss_fn(mlp(x), y).item())\n",
    "        mlp.train()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % (50000 // 150) == 0:\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "30cb023e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8209fc09fee04910ae8be4e396e5b91d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5263883624151712\n",
      "0.0003362170206702667\n",
      "0.00015088362667050025\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da19cdc586cb4d81b5a59f808339eee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00012676368556867966\n",
      "0.00012194118928237454\n",
      "0.0001255159316271821\n",
      "0.00012137283877122483\n",
      "0.00012750735077963178\n",
      "0.00012525445867335753\n",
      "0.00012437193717520608\n",
      "0.0001225545109952248\n",
      "0.00012555452786392664\n",
      "0.000121931088749985\n",
      "0.00012246149057976367\n",
      "0.00012350623566652303\n",
      "0.0001259862378476408\n",
      "0.00012145821352066536\n",
      "0.00012534931718205901\n",
      "0.00012244558787481426\n",
      "0.00012260972304645442\n",
      "0.00012509016479348085\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37523/3816812015.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmse_loss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 5000\n",
    "\n",
    "def batch_loader(N=batch_size, device=device, dtype=dtype):\n",
    "    x = torch.rand((N, 1), device=device, dtype=dtype)\n",
    "    return x, x\n",
    "\n",
    "width = 500\n",
    "mlp = nn.Sequential(\n",
    "    nn.Linear(1, width),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(width, width),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(width, width),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(width, 1)\n",
    ").to(device)\n",
    "mlp.train()\n",
    "\n",
    "rmse_loss_fn = lambda x, y: torch.sqrt(torch.mean(torch.pow(x - y, 2)))\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(mlp.parameters())\n",
    "\n",
    "for i in tqdm(range(500)):\n",
    "    optimizer.zero_grad()\n",
    "    x, y = batch_loader(batch_size)\n",
    "    loss = loss_fn(mlp(x), y)\n",
    "    if i % 200 == 0:\n",
    "        mlp.eval()\n",
    "        with torch.no_grad():\n",
    "            print(rmse_loss_fn(mlp(x), y).item())\n",
    "        mlp.train()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "def get_loss_on(x, y):\n",
    "    def loss():\n",
    "        return loss_fn(mlp(x), y)\n",
    "    return loss\n",
    "\n",
    "optimizer = torch.optim.LBFGS(mlp.parameters(), \n",
    "                              max_iter=50, \n",
    "                              tolerance_grad=1e-7,\n",
    "#                               tolerance_change=1e-12,\n",
    "                              line_search_fn='strong_wolfe')\n",
    "    \n",
    "for i in tqdm(range(30)):\n",
    "    optimizer.zero_grad()\n",
    "    x, y = batch_loader(batch_size)\n",
    "    loss = loss_fn(mlp(x), y)\n",
    "    if i % 5 == 0:\n",
    "        mlp.eval()\n",
    "        with torch.no_grad():\n",
    "            print(rmse_loss_fn(mlp(x), y).item())\n",
    "        mlp.train()\n",
    "    loss.backward()\n",
    "    optimizer.step(get_loss_on(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "da0ed14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.optim.LBFGS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fde7568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91ec59e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cda29a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc98c411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a20511d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4505097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513e1472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1b97e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2402cf64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0c3f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db16d14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10ff0fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
